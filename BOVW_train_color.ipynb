{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model using BOVW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color'\n",
    "training_names = [training_name for training_name in os.listdir(train_path) if not training_name.endswith('.csv')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat', 'Dog']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "image_classes = []\n",
    "class_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imglist(path):    \n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for training_name in training_names:\n",
    "    dir = os.path.join(train_path, training_name)\n",
    "    class_path = imglist(dir)\n",
    "    image_paths+=class_path\n",
    "    image_classes+=[class_id]*len(class_path)\n",
    "    class_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List where all the descriptors will be stored\n",
    "des_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BRISK is a good replacement to SIFT\n",
    "brisk = cv2.BRISK_create(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/10125.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/10404.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/10501.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/10820.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/140.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 214 extraneous bytes before marker 0xd9\n",
      "Corrupt JPEG data: 128 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors are None for image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/2433.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/2663.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/3300.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/3491.jpg\n",
      "Descriptors are None for image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/4821.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/4833.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/5553.jpg\n",
      "Error resizing image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/5673.jpg\n",
      "Descriptors are None for image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/6402.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 99 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/660.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 1153 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/7968.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/7978.jpg\n",
      "Descriptors are None for image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/835.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/8470.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/850.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/9171.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/936.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/9565.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Cat/9778.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/10158.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/10401.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/10747.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/10797.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/1308.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/1866.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/2384.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/2688.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/2877.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 226 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/3136.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/3288.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/3588.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 162 extraneous bytes before marker 0xd9\n",
      "Warning: unknown JFIF revision number 0.00\n",
      "Corrupt JPEG data: 1403 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/5604.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/5736.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/6059.jpg\n",
      "Descriptors are None for image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/612.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/6238.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/6718.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/7112.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/7133.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/7369.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/7459.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: 65 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/7969.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/8730.jpg\n",
      "Failed to load image: /media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Train_Color/Dog/9188.jpg\n",
      "Feature extraction completed!\n"
     ]
    }
   ],
   "source": [
    "# Iterate through all image paths\n",
    "# Remove all bad images then create good list then rerun earlier code\n",
    "for image_path in image_paths:\n",
    "    # Read the image\n",
    "    im = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if image is valid\n",
    "    if im is not None:\n",
    "        try:\n",
    "            # Detect and compute keypoints and descriptors\n",
    "            kpts, des = brisk.detectAndCompute(im, None)\n",
    "            \n",
    "            # Check if descriptors are valid\n",
    "            if des is not None:\n",
    "                # Append image path and descriptors to list\n",
    "                des_list.append((image_path, des))\n",
    "            else:\n",
    "                print(f\"Descriptors are None for image: {image_path}\")\n",
    "        except cv2.error as e:\n",
    "            if 'resize' in str(e):\n",
    "                print(f\"Error resizing image: {image_path}\")\n",
    "            else:\n",
    "                print(f\"Error processing image: {image_path}, Error: {e}\")\n",
    "    else:\n",
    "        print(f\"Failed to load image: {image_path}\")\n",
    "\n",
    "print(\"Feature extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptors stacked successfully!\n"
     ]
    }
   ],
   "source": [
    "# Extract descriptors from des_list\n",
    "descriptor_list = [descriptor for _, descriptor in des_list]\n",
    "\n",
    "# Stack all the descriptors vertically in a numpy array\n",
    "descriptors = np.concatenate(descriptor_list, axis=0)\n",
    "\n",
    "print(\"Descriptors stacked successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans works only on float, so convert integers to float\n",
    "descriptors_float = descriptors.astype(float)  \n",
    "\n",
    "# Perform k-means clustering and vector quantization\n",
    "from scipy.cluster.vq import kmeans, vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping index 21947: Descriptor list is incomplete.\n",
      "Skipping index 21948: Descriptor list is incomplete.\n",
      "Skipping index 21949: Descriptor list is incomplete.\n",
      "Skipping index 21950: Descriptor list is incomplete.\n",
      "Skipping index 21951: Descriptor list is incomplete.\n",
      "Skipping index 21952: Descriptor list is incomplete.\n",
      "Skipping index 21953: Descriptor list is incomplete.\n",
      "Skipping index 21954: Descriptor list is incomplete.\n",
      "Skipping index 21955: Descriptor list is incomplete.\n",
      "Skipping index 21956: Descriptor list is incomplete.\n",
      "Skipping index 21957: Descriptor list is incomplete.\n",
      "Skipping index 21958: Descriptor list is incomplete.\n",
      "Skipping index 21959: Descriptor list is incomplete.\n",
      "Skipping index 21960: Descriptor list is incomplete.\n",
      "Skipping index 21961: Descriptor list is incomplete.\n",
      "Skipping index 21962: Descriptor list is incomplete.\n",
      "Skipping index 21963: Descriptor list is incomplete.\n",
      "Skipping index 21964: Descriptor list is incomplete.\n",
      "Skipping index 21965: Descriptor list is incomplete.\n",
      "Skipping index 21966: Descriptor list is incomplete.\n",
      "Skipping index 21967: Descriptor list is incomplete.\n",
      "Skipping index 21968: Descriptor list is incomplete.\n",
      "Skipping index 21969: Descriptor list is incomplete.\n",
      "Skipping index 21970: Descriptor list is incomplete.\n",
      "Skipping index 21971: Descriptor list is incomplete.\n",
      "Skipping index 21972: Descriptor list is incomplete.\n",
      "Skipping index 21973: Descriptor list is incomplete.\n",
      "Skipping index 21974: Descriptor list is incomplete.\n",
      "Skipping index 21975: Descriptor list is incomplete.\n",
      "Skipping index 21976: Descriptor list is incomplete.\n",
      "Skipping index 21977: Descriptor list is incomplete.\n",
      "Skipping index 21978: Descriptor list is incomplete.\n",
      "Skipping index 21979: Descriptor list is incomplete.\n",
      "Skipping index 21980: Descriptor list is incomplete.\n",
      "Skipping index 21981: Descriptor list is incomplete.\n",
      "Skipping index 21982: Descriptor list is incomplete.\n",
      "Skipping index 21983: Descriptor list is incomplete.\n",
      "Skipping index 21984: Descriptor list is incomplete.\n",
      "Skipping index 21985: Descriptor list is incomplete.\n",
      "Skipping index 21986: Descriptor list is incomplete.\n",
      "Skipping index 21987: Descriptor list is incomplete.\n",
      "Skipping index 21988: Descriptor list is incomplete.\n",
      "Skipping index 21989: Descriptor list is incomplete.\n",
      "Skipping index 21990: Descriptor list is incomplete.\n",
      "Skipping index 21991: Descriptor list is incomplete.\n",
      "Skipping index 21992: Descriptor list is incomplete.\n",
      "Skipping index 21993: Descriptor list is incomplete.\n",
      "Skipping index 21994: Descriptor list is incomplete.\n",
      "Skipping index 21995: Descriptor list is incomplete.\n"
     ]
    }
   ],
   "source": [
    "k = 50  \n",
    "voc, variance = kmeans(descriptors_float, k, 1) \n",
    "\n",
    "# Calculate the histogram of features and represent them as vector\n",
    "im_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "for i in range(len(image_paths)):\n",
    "    if i >= len(des_list) or len(des_list[i]) < 2:\n",
    "        print(f\"Skipping index {i}: Descriptor list is incomplete.\")\n",
    "        continue\n",
    "\n",
    "    words, distance = vq(des_list[i][1], voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20770714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptors_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m----> 2\u001b[0m voc, variance \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescriptors_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "File \u001b[0;32m~/anaconda3/envs/catdog/lib/python3.9/site-packages/scipy/cluster/vq.py:495\u001b[0m, in \u001b[0;36mkmeans\u001b[0;34m(obs, k_or_guess, iter, thresh, check_finite, seed)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28miter\u001b[39m):\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;66;03m# the initial code book is randomly selected from observations\u001b[39;00m\n\u001b[1;32m    494\u001b[0m     guess \u001b[38;5;241m=\u001b[39m _kpoints(obs, k, rng, xp)\n\u001b[0;32m--> 495\u001b[0m     book, dist \u001b[38;5;241m=\u001b[39m \u001b[43m_kmeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;241m<\u001b[39m best_dist:\n\u001b[1;32m    497\u001b[0m         best_book \u001b[38;5;241m=\u001b[39m book\n",
      "File \u001b[0;32m~/anaconda3/envs/catdog/lib/python3.9/site-packages/scipy/cluster/vq.py:313\u001b[0m, in \u001b[0;36m_kmeans\u001b[0;34m(obs, guess, thresh, xp)\u001b[0m\n\u001b[1;32m    310\u001b[0m prev_avg_dists \u001b[38;5;241m=\u001b[39m deque([diff], maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m diff \u001b[38;5;241m>\u001b[39m thresh:\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;66;03m# compute membership and distances between obs and code_book\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     obs_code, distort \u001b[38;5;241m=\u001b[39m \u001b[43mvq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_book\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     prev_avg_dists\u001b[38;5;241m.\u001b[39mappend(xp\u001b[38;5;241m.\u001b[39mmean(distort, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;66;03m# recalc code_book as centroids of associated obs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/catdog/lib/python3.9/site-packages/scipy/cluster/vq.py:215\u001b[0m, in \u001b[0;36mvq\u001b[0;34m(obs, code_book, check_finite)\u001b[0m\n\u001b[1;32m    213\u001b[0m     c_obs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(c_obs)\n\u001b[1;32m    214\u001b[0m     c_code_book \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(c_code_book)\n\u001b[0;32m--> 215\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_vq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_code_book\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(result[\u001b[38;5;241m0\u001b[39m]), xp\u001b[38;5;241m.\u001b[39masarray(result[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m py_vq(obs, code_book, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 200\n",
    "voc, variance = kmeans(descriptors_float, k, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the histogram of features and represent them as vector\n",
    "#vq Assigns codes from a code book to observations.\n",
    "im_features = np.zeros((len(image_paths), k), \"float32\")\n",
    "for i in range(len(image_paths)):\n",
    "    if i >= len(des_list) or len(des_list[i]) < 2:\n",
    "        print(f\"Skipping index {i}: Descriptor list is incomplete.\")\n",
    "        continue\n",
    "\n",
    "    words, distance = vq(des_list[i][1], voc)\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Tf-Idf vectorization\n",
    "nbr_occurences = np.sum( (im_features > 0) * 1, axis = 0)\n",
    "idf = np.array(np.log((1.0*len(image_paths)+1) / (1.0*nbr_occurences + 1)), 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the words\n",
    "#Standardize features by removing the mean and scaling to unit variance\n",
    "#In a way normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stdSlr = StandardScaler().fit(im_features)\n",
    "im_features = stdSlr.transform(im_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/anaconda3/envs/catdog/lib/python3.9/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ryan/anaconda3/envs/catdog/lib/python3.9/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(max_iter=10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train an algorithm to discriminate vectors corresponding to positive and negative training images\n",
    "# Train the Linear SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(max_iter=10000)  #Default of 100 is not converging\n",
    "clf.fit(im_features, np.array(image_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Models/bovw_brisk.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the SVM\n",
    "#Joblib dumps Python object into one file\n",
    "import joblib\n",
    "joblib.dump((clf, training_names, stdSlr, k, voc), \"/media/ryan/New Volume/datasets/kagglecatsanddogs_5340/PetImages/Models/bovw_color_brisk.pkl\", compress=3)    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catdog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
